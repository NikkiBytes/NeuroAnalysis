{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroimaging Data: Understanding input and output  \n",
    "Nilearn can operate on either filenames or NiftiImage objects. NiftiImage objects represent data loaded in memory. \n",
    "\n",
    "##### Neuroimaging images, *a.k.a niimgs*, come in these formats:  \n",
    "- 3D images, containing a single brain volume  \n",
    "- 4D images, containing multiple brain volumes. (ie a time series of 3D images, or a list of files names containing 3D info)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nilearn functions accept either 3D or 4D images:  \n",
    "- **`nilearn.image.index_img` || `nilearn.image.iter_img`** breaks down **4D** images into **3D** images.  \n",
    "- **`nilearn.image.concat_imgs`** groups a list of **3D** images into a **4D** image.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding neuroimaging data  \n",
    "#### Nifti and Analyze data\n",
    "For volumetric data, nilearn works with data stored as in the **Nifti** structure (via the `nibabel` package).  \n",
    "  \n",
    "The Nifti data structure is the standard way of sharing data in neuroimaging research, it is also used in Analyze files.  \n",
    "##### The main 3 components are:  \n",
    "- **data:** raw scans in the form of a *numpy array*  \n",
    "          \n",
    "        data = img.get_data()\n",
    "  \n",
    "\n",
    "- **affine:** returns the **transformation matrix** that maps from voxel indices of the numpy array to actual real-world locations of the brain  \n",
    "\n",
    "        affine = img.affine\n",
    "  \n",
    "  \n",
    "- **header:** low-level informations about the data (slice duration, etc.)  \n",
    "\n",
    "        header = img.header\n",
    "  \n",
    "  \n",
    "  \n",
    "##### Dataset formatting: data shape  \n",
    "Appreciate two main representations for storing and accessing more than one Nifti images, **that is sets of MRI scans:** . \n",
    "- a large 4D matrix representing (3D MRI + 1D for time) , stored in a single Nifti file. *FSL users tend to prefer this format.*  \n",
    "- several 3D matrices representing each time point (single 3D volume) of the session, sotred in set of 3D Nifti or analyse files. *SPM users tend to prefer this format.*  \n",
    "\n",
    "##### Niimg-like objects  \n",
    "**Niimg:** A Niimg-like object can be:\n",
    "- A string with a file path to a Nifti or Analyse image  \n",
    "- An `SpatialImage` from `nibabel`, ie an object exposing `get_data()` method and `affine` attribute, typically a Nifti1Image from `nibabel`.  \n",
    "  \n",
    "**Niimg-4D:** Some functions require 4D Nifti-like data, called Niimgs or Niimg-4D. Accepted input arguments are ...  \n",
    "- A path to a 4D Nifti image  \n",
    "- List of paths to 3D Nifti images  \n",
    "- 4D Nifti-like object  \n",
    "- List of 3D Nifti-like objects  \n",
    "\n",
    "**Image affines- if you provide a sequence of Nifti images, all of them must have the same affine.**  \n",
    "  \n",
    "  \n",
    "#### Text files: phenotype or behavior  \n",
    "  \n",
    "Phenotypic or behavioral data are often provided as text or CSV(Comma Separated Values) file. They can be loaded with `pandas.read_csv` -- note you may have to specify some options(often `sep` if fields are delimited with a comma).  \n",
    "##### Reading CSV with pandas  \n",
    "Pandas is a powerful package to read data from CSV files and manipulate them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rest' 'scissors' 'face' 'cat' 'shoe' 'house' 'scrambledpix' 'bottle'\n",
      " 'chair']\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "import pandas as pd\n",
    "labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "stimuli = labels['labels']\n",
    "print(stimuli.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "I. http://nilearn.github.io/manipulating_images/input_output.html#loading-data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
