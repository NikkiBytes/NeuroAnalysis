{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- import packages --\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold,  cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean,std\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sucrose infusions csv dataframe, locally set path\n",
    "path=\"C:\\\\Users\\\\19802\\\\Documents\\\\nibl\\\\pilot_connectivity\\\\mouse_data\\\\Sucrose_infusions_full_df.csv\" \n",
    "data=pd.read_csv(path) # read in as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] data columns: \n",
      "\n",
      "['Time(s)' 'PFC_delta' 'PFC_theta' 'PFC_alpha' 'PFC_beta' 'PFC_low_gamma'\n",
      " 'PFC_high_gamma' 'BLA_delta' 'BLA_theta' 'BLA_alpha' 'BLA_beta'\n",
      " 'BLA_low_gamma' 'BLA_high_gamma' 'NAc_delta' 'NAc_theta' 'NAc_alpha'\n",
      " 'NAc_beta' 'NAc_low_gamma' 'NAc_high_gamma' 'vHip_delta' 'vHip_theta'\n",
      " 'vHip_alpha' 'vHip_beta' 'vHip_low_gamma' 'vHip_high_gamma' 'Reward'\n",
      " 'MouseId' 'Treatment']     \n",
      "\n",
      "[INFO] reward: ['None' 'Water' 'Sucrose_5' 'Sucrose_15']       \n",
      "\n",
      "[INFO] mouse IDs: ['E_A1' 'E_A3' 'E_A7' 'E_A8'] \n",
      "       \n",
      "\n",
      "[INFO] treatment: ['Post_HFD' 'Post_removal' 'Pre_HFD'] \n",
      "       \n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# -- print data info -- \n",
    "print(\"\\n[INFO] data columns: \\n\\n%s \\\n",
    "    \\n\\n[INFO] reward: %s \\\n",
    "      \\n\\n[INFO] mouse IDs: %s \\n \\\n",
    "      \\n\\n[INFO] treatment: %s \\n \\\n",
    "      \\n\\n \"%(data.columns.values,\n",
    "                data[\"Reward\"].unique(), \n",
    "                data['MouseId'].unique(),\n",
    "                data['Treatment'].unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data  \n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy variables**  \n",
    "We use pandas package `get_dummies()` , passing the dataframe and the columns to convert: \"MouseId\" and \"Treatment\".   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E_A1', 'E_A3', 'E_A7', 'E_A8'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['MouseId'].unique() # View unique mouse ID labels in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- label encoder on our data -- \n",
    "#le = preprocessing.LabelEncoder() # initialize encoder obj\n",
    "#data['MouseId'] = le.fit_transform(data['MouseId']) # fit and transform the 5% data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.get_dummies(data, columns=[\"MouseId\"]) # convert to dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MouseId_E_A1</th>\n",
       "      <th>MouseId_E_A3</th>\n",
       "      <th>MouseId_E_A7</th>\n",
       "      <th>MouseId_E_A8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MouseId_E_A1  MouseId_E_A3  MouseId_E_A7  MouseId_E_A8\n",
       "0             1             0             0             0\n",
       "1             1             0             0             0\n",
       "2             1             0             0             0\n",
       "3             1             0             0             0\n",
       "4             1             0             0             0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(like=\"MouseId\", axis=1).head() # view the new dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Post_HFD', 'Post_removal', 'Pre_HFD'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Treatment'].unique()  # View unique treatment labels in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- label encoder on our data -- \n",
    "#le = preprocessing.LabelEncoder() # initialize encoder obj\n",
    "#data['Treatment'] = le.fit_transform(data['Treatment']) # fit and transform the 5% data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Post_HFD', 'Post_removal', 'Pre_HFD'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Treatment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.get_dummies(data, columns=[\"Treatment\"]) # convert to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treatment_Post_HFD</th>\n",
       "      <th>Treatment_Post_removal</th>\n",
       "      <th>Treatment_Pre_HFD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Treatment_Post_HFD  Treatment_Post_removal  Treatment_Pre_HFD\n",
       "0                   1                       0                  0\n",
       "1                   1                       0                  0\n",
       "2                   1                       0                  0\n",
       "3                   1                       0                  0\n",
       "4                   1                       0                  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(like=\"Treatment\", axis=1).head() # view the new dummy/indicator variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Time(s)', 'PFC_delta', 'PFC_theta', 'PFC_alpha', 'PFC_beta',\n",
       "       'PFC_low_gamma', 'PFC_high_gamma', 'BLA_delta', 'BLA_theta',\n",
       "       'BLA_alpha', 'BLA_beta', 'BLA_low_gamma', 'BLA_high_gamma',\n",
       "       'NAc_delta', 'NAc_theta', 'NAc_alpha', 'NAc_beta', 'NAc_low_gamma',\n",
       "       'NAc_high_gamma', 'vHip_delta', 'vHip_theta', 'vHip_alpha',\n",
       "       'vHip_beta', 'vHip_low_gamma', 'vHip_high_gamma', 'Reward',\n",
       "       'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
       "       'Treatment_Post_HFD', 'Treatment_Post_removal',\n",
       "       'Treatment_Pre_HFD'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values # view new columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] new dummy data: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time(s)</th>\n",
       "      <th>PFC_delta</th>\n",
       "      <th>PFC_theta</th>\n",
       "      <th>PFC_alpha</th>\n",
       "      <th>PFC_beta</th>\n",
       "      <th>PFC_low_gamma</th>\n",
       "      <th>PFC_high_gamma</th>\n",
       "      <th>BLA_delta</th>\n",
       "      <th>BLA_theta</th>\n",
       "      <th>BLA_alpha</th>\n",
       "      <th>BLA_beta</th>\n",
       "      <th>BLA_low_gamma</th>\n",
       "      <th>BLA_high_gamma</th>\n",
       "      <th>NAc_delta</th>\n",
       "      <th>NAc_theta</th>\n",
       "      <th>NAc_alpha</th>\n",
       "      <th>NAc_beta</th>\n",
       "      <th>NAc_low_gamma</th>\n",
       "      <th>NAc_high_gamma</th>\n",
       "      <th>vHip_delta</th>\n",
       "      <th>vHip_theta</th>\n",
       "      <th>vHip_alpha</th>\n",
       "      <th>vHip_beta</th>\n",
       "      <th>vHip_low_gamma</th>\n",
       "      <th>vHip_high_gamma</th>\n",
       "      <th>Reward</th>\n",
       "      <th>MouseId_E_A1</th>\n",
       "      <th>MouseId_E_A3</th>\n",
       "      <th>MouseId_E_A7</th>\n",
       "      <th>MouseId_E_A8</th>\n",
       "      <th>Treatment_Post_HFD</th>\n",
       "      <th>Treatment_Post_removal</th>\n",
       "      <th>Treatment_Pre_HFD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.757425e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.524725e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.023675e-07</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>7.751850e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.334475e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.507175e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.345025e-07</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>9.978000e-07</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.912275e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.596450e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.725375e-07</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.241688e-06</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time(s)  PFC_delta  PFC_theta     PFC_alpha  PFC_beta  PFC_low_gamma  \\\n",
       "0      0.0   0.000002   0.000007  2.757425e-07  0.000002       0.000001   \n",
       "1      0.1   0.000002   0.000007  2.334475e-07  0.000002       0.000001   \n",
       "2      0.2   0.000003   0.000007  2.912275e-07  0.000001       0.000001   \n",
       "\n",
       "   PFC_high_gamma  BLA_delta  BLA_theta  BLA_alpha  BLA_beta  BLA_low_gamma  \\\n",
       "0    2.524725e-07   0.000002   0.000006   0.000005  0.000005       0.000007   \n",
       "1    2.507175e-07   0.000001   0.000006   0.000004  0.000005       0.000007   \n",
       "2    2.596450e-07   0.000002   0.000006   0.000004  0.000005       0.000007   \n",
       "\n",
       "   BLA_high_gamma  NAc_delta  NAc_theta  NAc_alpha  NAc_beta  NAc_low_gamma  \\\n",
       "0    4.023675e-07   0.000107   0.000025   0.000009  0.000011       0.000008   \n",
       "1    4.345025e-07   0.000102   0.000021   0.000009  0.000011       0.000007   \n",
       "2    4.725375e-07   0.000100   0.000023   0.000010  0.000012       0.000008   \n",
       "\n",
       "   NAc_high_gamma  vHip_delta  vHip_theta  vHip_alpha  vHip_beta  \\\n",
       "0        0.000001    0.000068    0.000094    0.000014   0.000019   \n",
       "1        0.000001    0.000046    0.000093    0.000018   0.000021   \n",
       "2        0.000001    0.000018    0.000104    0.000031   0.000036   \n",
       "\n",
       "   vHip_low_gamma  vHip_high_gamma Reward  MouseId_E_A1  MouseId_E_A3  \\\n",
       "0        0.000008     7.751850e-07   None             1             0   \n",
       "1        0.000009     9.978000e-07   None             1             0   \n",
       "2        0.000014     2.241688e-06   None             1             0   \n",
       "\n",
       "   MouseId_E_A7  MouseId_E_A8  Treatment_Post_HFD  Treatment_Post_removal  \\\n",
       "0             0             0                   1                       0   \n",
       "1             0             0                   1                       0   \n",
       "2             0             0                   1                       0   \n",
       "\n",
       "   Treatment_Pre_HFD  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n[INFO] new dummy data: \\n\\n\")\n",
    "display(data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup target variables Y    \n",
    "  \n",
    "Currently we will set up two target conditions:    \n",
    "- Water vs. Sucrose 5%, y_s5  \n",
    "- Water vs. Sucrose 15%, y_s15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Water', 'Sucrose_5'], dtype=object),\n",
       " array(['Water', 'Sucrose_15'], dtype=object))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- Setup the target variables  --\n",
    "\n",
    "Y = data.loc[:, \"Reward\"] # set copy of target variable to Y \n",
    "\n",
    "# make condition masks for Water vs. Sucrose %5 and Water vs. Sucorse vs 15%\n",
    "s5_cond_mask=Y.isin(['Water', \"Sucrose_5\"])\n",
    "s15_cond_mask=Y.isin(['Water', \"Sucrose_15\"])\n",
    "\n",
    "# filter data for target variabes w/ condition masks\n",
    "y_s5=Y[s5_cond_mask]\n",
    "y_s15=Y[s15_cond_mask]\n",
    "\n",
    "\n",
    "# prepare feature dataframe with filtered masks\n",
    "s5_data = data[s5_cond_mask]\n",
    "s15_data = data[s15_cond_mask]\n",
    "\n",
    "y_s5.unique(), y_s15.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3727    Water\n",
       " 3728    Water\n",
       " 3729    Water\n",
       " 3730    Water\n",
       " 3731    Water\n",
       " Name: Reward, dtype: object,\n",
       " 3727    Water\n",
       " 3728    Water\n",
       " 3729    Water\n",
       " 3730    Water\n",
       " 3731    Water\n",
       " Name: Reward, dtype: object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_s5.head(), y_s15.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12291,), (12342,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- label encoder on our data -- \n",
    "le = preprocessing.LabelEncoder() # initialize encoder obj\n",
    "y_s5_enc = le.fit_transform(y_s5) # fit and transform the 5% data\n",
    "y_s15_enc = le.fit_transform(y_s15) # fit and transform the 15% data\n",
    "\n",
    "y_s5_enc.shape, y_s15_enc.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1]), array([1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_s5_enc[:5], y_s15_enc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing Classifiers\n",
    "clf1 = LogisticRegression(solver='liblinear', random_state=1)\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = DecisionTreeClassifier(random_state=1)\n",
    "clf4 = SVC(kernel='rbf', random_state=1)\n",
    "clf5 = SVC(kernel='linear', random_state=1)\n",
    "\n",
    "# Building the pipelines\n",
    "pipe1 = Pipeline([('std', StandardScaler()),\n",
    "                  ('clf1', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('std', StandardScaler()),\n",
    "                  ('clf2', clf2)])\n",
    "\n",
    "pipe4 = Pipeline([('std', StandardScaler()),\n",
    "                  ('clf4', clf4)])\n",
    "\n",
    "pipe5 = Pipeline([('std', StandardScaler()),\n",
    "                  ('clf5', clf5)])\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid1 = [{'clf1__penalty': ['l1', 'l2'],\n",
    "                'clf1__C': np.power(10., np.arange(-4, 4))}]\n",
    "\n",
    "param_grid2 = [{'clf2__n_neighbors': list(range(1, 10)),\n",
    "                'clf2__p': [1, 2]}]\n",
    "\n",
    "param_grid3 = [{'max_depth': list(range(1, 10)) + [None],\n",
    "                'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "param_grid4 = [{'clf4__C': np.power(10., np.arange(-4, 4)),\n",
    "                'clf4__gamma': np.power(10., np.arange(-5, 0))}]\n",
    "\n",
    "param_grid5 = [{'clf5__C': np.power(10., np.arange(-4, 4))}]\n",
    "\n",
    "# Setting up multiple GridSearchCV objects as inner CV, 1 for each algorithm\n",
    "gridcvs = {}\n",
    "inner_cv = KFold(n_splits=10)\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2,\n",
    "                             param_grid3, param_grid4, param_grid5),\n",
    "                            (pipe1, pipe2, pipe3, pipe4, pipe5),\n",
    "                            ('Logit', 'KNN', 'DTree', 'SVMRBF', 'SVMLINEAR')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=1,\n",
    "                       cv=inner_cv,\n",
    "                       verbose=0,\n",
    "                       refit=True)\n",
    "    gridcvs[name] = gcv\n",
    "    \n",
    "\n",
    "# Making an outer CV\n",
    "outer_cv = KFold(n_splits=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Input Features X  \n",
    "We are analyzing the data by region and bands.  \n",
    "Currently we focus here on `low gamma` and `theta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PFC_low_gamma</th>\n",
       "      <th>BLA_low_gamma</th>\n",
       "      <th>NAc_low_gamma</th>\n",
       "      <th>vHip_low_gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PFC_low_gamma  BLA_low_gamma  NAc_low_gamma  vHip_low_gamma\n",
       "0       0.000001       0.000007       0.000008        0.000008\n",
       "1       0.000001       0.000007       0.000007        0.000009\n",
       "2       0.000001       0.000007       0.000008        0.000014\n",
       "3       0.000001       0.000007       0.000008        0.000008\n",
       "4       0.000002       0.000007       0.000009        0.000009"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(like=\"low_gamma\", axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize scaler object\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low Gamma \n",
    "> NAc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Nac -- \n",
    "s5_lgnac_data=s5_data[[\"NAc_low_gamma\", 'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                       'Treatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']]# 'MouseId','Treatment']] \n",
    "s15_lgnac_data=s15_data[[\"NAc_low_gamma\",'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                       'Trzeatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "\n",
    "X_s5_lgnac = scaler.fit_transform(s5_lgnac_data) # fit and transform \n",
    "X_s15_lgnac = scaler.fit_transform(s15_lgnac_data) # fit and transform\n",
    "\n",
    "\n",
    "# Making train set for Nested CV and test set for final model evaluation\n",
    "X_train_s5_lgpfc, X_test_s5_lgpfc, y_train_s5_lgpfc, y_test_s15_lgpfc = train_test_split(X_s5_lgpfc, y_s5_enc,\n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1, shuffle=True)\n",
    "                                                                                         \n",
    "                                                    #stratify= y_s15_enc)\n",
    "X_train_s15_lgpfc, X_test_s15_lgpfc, y_train_s15_lgpfc, y_test_s15_lgpfc = train_test_split(X_s15_lgpfc, y_s15_enc,\n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    nested_score = cross_val_score(gs_est, \n",
    "                                   X=X_train_s15_lgpfc, \n",
    "                                   y=y_train_s15_lgpfc, \n",
    "                                   cv=outer_cv,\n",
    "                                   n_jobs=1)\n",
    "    print('%s | outer ACC %.2f%% +/- %.2f' % \n",
    "          (name, nested_score.mean() * 100, nested_score.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fitting a model to the whole training set using the \"best\" algorithm\n",
    "best_algo = gridcvs['SVM']\n",
    "\n",
    "best_algo.fit(X_train_s5, y_train_s5)\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train_s5, y_pred=best_algo.predict(X_train_s5))\n",
    "test_acc = accuracy_score(y_true=y_test_s5, y_pred=best_algo.predict(X_test_s5))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV train folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['SVM'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low Gamma  \n",
    "> All Regions: vHip, BLA, PFC, NAc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- setup low gamma --\n",
    "\n",
    "\n",
    "\n",
    "# -- vHip -- \n",
    "\n",
    "s5_lghip_data=s5_data[[\"vHip_low_gamma\", 'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                       'Treatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "s15_lghip_data=s15_data[[\"vHip_low_gamma\", 'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                       'Treatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "\n",
    "\n",
    "X_s5_lghip = scaler.fit_transform(s5_lghip_data) # fit and transform \n",
    "X_s15_lghip = scaler.fit_transform(s15_lghip_data) # fit and transform \n",
    "\n",
    "\n",
    "# Making train set for Nested CV and test set for final model evaluation\n",
    "X_train_s15_lgpfc, X_test_s15_lgpfc, y_train_s15_lgpfc, y_test_s15_lgpfc = train_test_split(X_s15_lgpfc, y_s15_enc,\n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify= y_s15_enc)\n",
    "\n",
    "# -- BLA -- \n",
    "s5_lgbla_data=s5_data[[\"BLA_low_gamma\", 'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                       'Treatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "s15_lgbla_data=s15_data[[\"BLA_low_gamma\",'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8', \n",
    "                         'Treatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']] #'MouseId','Treatment']]  \n",
    "\n",
    "X_s5_lgbla = scaler.fit_transform(s5_lgbla_data) # fit and transform \n",
    "X_s15_lgbla = scaler.fit_transform(s15_lgbla_data) # fit and transform \n",
    "\n",
    "\n",
    "# Making train set for Nested CV and test set for final model evaluation\n",
    "X_train_s5, X_test_s5, y_train_s5, y_test_s5 = train_test_split(X_s5_lgbla, y_s5_enc,\n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify= y_s5_enc)\n",
    "\n",
    "# Making train set for Nested CV and test set for final model evaluation\n",
    "X_train_s15, X_test_s15, y_train_s15, y_test_s15 = train_test_split(X_s15_lgbla, y_s15_enc,\n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify= y_s15_enc)\n",
    "\n",
    "# -- PFC  -- \n",
    "s5_lgpfc_data=s5_data[[\"PFC_low_gamma\",  'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                   'Treatment_Post_HFD', 'Treatment_Post_removal','Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "s15_lgpfc_data=s15_data[[\"PFC_low_gamma\",'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                   'Treatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "\n",
    "X_s5_lgpfc = scaler.fit_transform(s5_lgpfc_data) # fit and transform \n",
    "X_s15_lgpfc = scaler.fit_transform(s15_lgpfc_data) # fit and transform\n",
    "\n",
    "\n",
    "# Making train set for Nested CV and test set for final model evaluation\n",
    "X_train_s15_lgpfc, X_test_s15_lgpfc, y_train_s15_lgpfc, y_test_s15_lgpfc = train_test_split(X_s15_lgpfc, y_s15_enc,\n",
    "                                                    train_size=0.8, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify= y_s15_enc)\n",
    "\n",
    "\n",
    "# -- ALL REGIONS -- \n",
    "s5_lgall_data=s5_data[[\"PFC_low_gamma\", \"NAc_low_gamma\",\"vHip_low_gamma\", \"BLA_low_gamma\", 'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                   'Treatment_Post_HFD', 'Treatment_Post_removal','Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "s15_lgall_data=s15_data[[\"PFC_low_gamma\", \"NAc_low_gamma\",\"vHip_low_gamma\", \"BLA_low_gamma\", 'MouseId_E_A1', 'MouseId_E_A3', 'MouseId_E_A7', 'MouseId_E_A8',\n",
    "                   'Treatment_Post_HFD', 'Treatment_Post_removal', 'Treatment_Pre_HFD']] #'MouseId','Treatment']] \n",
    "\n",
    "X_s5_lgall = scaler.fit_transform(s5_lgall_data) # fit and transform \n",
    "X_s15_lgall = scaler.fit_transform(s15_lgall_data) # fit and transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Low Gamma PFC, Water vs. 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    nested_score = cross_val_score(gs_est, \n",
    "                                   X=X_train_s15_lgpfc, \n",
    "                                   y=y_train_s15_lgpfc, \n",
    "                                   cv=outer_cv,\n",
    "                                   n_jobs=1)\n",
    "    print('%s | outer ACC %.2f%% +/- %.2f' % \n",
    "          (name, nested_score.mean() * 100, nested_score.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fitting a model to the whole training set using the \"best\" algorithm\n",
    "best_algo = gridcvs['SVM']\n",
    "\n",
    "best_algo.fit(X_train_s5, y_train_s5)\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train_s5, y_pred=best_algo.predict(X_train_s5))\n",
    "test_acc = accuracy_score(y_true=y_test_s5, y_pred=best_algo.predict(X_test_s5))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV train folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['SVM'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree | outer ACC 58.40% +/- 0.55\n",
      "KNN | outer ACC 58.52% +/- 0.58\n",
      "Logit | outer ACC 51.17% +/- 0.48\n",
      "SVM | outer ACC 58.63% +/- 1.07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Making an outer CV\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    nested_score = cross_val_score(gs_est, \n",
    "                                   X=X_train_s5, \n",
    "                                   y=y_train_s5, \n",
    "                                   cv=outer_cv,\n",
    "                                   n_jobs=1)\n",
    "    print('%s | outer ACC %.2f%% +/- %.2f' % \n",
    "          (name, nested_score.mean() * 100, nested_score.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 58.08% (average over CV train folds)\n",
      "Best Parameters: {'clf4__C': 1000.0, 'clf4__gamma': 0.1}\n",
      "Training Accuracy: 60.32%\n",
      "Test Accuracy: 58.24%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fitting a model to the whole training set using the \"best\" algorithm\n",
    "best_algo = gridcvs['SVM']\n",
    "\n",
    "best_algo.fit(X_train_s5, y_train_s5)\n",
    "\n",
    "train_acc = accuracy_score(y_true=y_train_s5, y_pred=best_algo.predict(X_train_s5))\n",
    "test_acc = accuracy_score(y_true=y_test_s5, y_pred=best_algo.predict(X_test_s5))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV train folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['SVM'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Low Gamma NAc Water vs. 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTree | outer ACC 56.57% +/- 0.76\n",
      "KNN | outer ACC 55.93% +/- 0.70\n",
      "Logit | outer ACC 51.43% +/- 0.87\n",
      "SVM | outer ACC 56.50% +/- 0.70\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Making an outer CV\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    nested_score = cross_val_score(gs_est, \n",
    "                                   X=X_train_s15, \n",
    "                                   y=y_train_s15, \n",
    "                                   cv=outer_cv,\n",
    "                                   n_jobs=1)\n",
    "    print('%s | outer ACC %.2f%% +/- %.2f' % \n",
    "          (name, nested_score.mean() * 100, nested_score.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=1, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('std', StandardScaler()),\n",
       "                                       ('clf4', SVC(random_state=1))]),\n",
       "             n_jobs=1,\n",
       "             param_grid=[{'clf4__C': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                          'clf4__gamma': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01])}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting a model to the whole training set using the \"best\" algorithm\n",
    "best_algo = gridcvs['SVM']\n",
    "\n",
    "best_algo.fit(X_train_s15, y_train_s15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 56.86% (average over CV train folds)\n",
      "Best Parameters: {'clf4__C': 1000.0, 'clf4__gamma': 0.1}\n",
      "Training Accuracy: 57.88%\n",
      "Test Accuracy: 57.63%\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy_score(y_true=y_train_s15, y_pred=best_algo.predict(X_train_s15))\n",
    "test_acc = accuracy_score(y_true=y_test_s15, y_pred=best_algo.predict(X_test_s15))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV train folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['SVM'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PFC_theta</th>\n",
       "      <th>BLA_theta</th>\n",
       "      <th>NAc_theta</th>\n",
       "      <th>vHip_theta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PFC_theta  BLA_theta  NAc_theta  vHip_theta\n",
       "0   0.000007   0.000006   0.000025    0.000094\n",
       "1   0.000007   0.000006   0.000021    0.000093\n",
       "2   0.000007   0.000006   0.000023    0.000104\n",
       "3   0.000007   0.000006   0.000025    0.000109\n",
       "4   0.000008   0.000007   0.000046    0.000117"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(like=\"theta\", axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(GridSearchCV(cv=KFold(n_splits=10, random_state=1, shuffle=True),\n",
       "              estimator=SVC(kernel='linear', max_iter=100000), n_jobs=3,\n",
       "              param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])},\n",
       "              scoring='accuracy', verbose=1),\n",
       " GridSearchCV(cv=KFold(n_splits=10, random_state=1, shuffle=True),\n",
       "              estimator=SVC(max_iter=10000), n_jobs=3,\n",
       "              param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                          'gamma': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])},\n",
       "              scoring='accuracy'),\n",
       " GridSearchCV(cv=KFold(n_splits=10, random_state=1, shuffle=True),\n",
       "              estimator=SVC(kernel='poly', max_iter=100000), n_jobs=3,\n",
       "              param_grid={'degree': [3, 5, 10, 15],\n",
       "                          'gamma': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])},\n",
       "              scoring='accuracy'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "\n",
    "    print(classification_report(y_true, y_pred)) # print classification report\n",
    "    return accuracy_score(y_true, y_pred); # return accuracy score\n",
    "\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# define the classifiers\n",
    "svc_linear = SVC(kernel='linear', max_iter=100000)\n",
    "svc_rbf = SVC(kernel='rbf', max_iter=10000)\n",
    "svc_poly = SVC(kernel=\"poly\", max_iter=100000)\n",
    "\n",
    "# define the hyperparameter grid\n",
    "C_range = np.logspace(-3, 2, 6)\n",
    "gamma_range = np.logspace(-3, 2, 6)\n",
    "poly_range = [3, 5, 10, 15]\n",
    "\n",
    "param_grid_linear = dict(C=C_range)\n",
    "param_grid_rbf = dict(gamma=gamma_range, C=C_range)\n",
    "param_grid_poly = dict(gamma=gamma_range, degree=poly_range )\n",
    "\n",
    "# set grid object\n",
    "grid_linear = GridSearchCV(svc_linear, param_grid_linear, scoring=\"accuracy\", verbose=1, n_jobs=3, cv=cv_inner)\n",
    "grid_rbf = GridSearchCV(svc_rbf,param_grid_rbf , scoring='accuracy', n_jobs=3, cv=cv_inner)\n",
    "grid_poly = GridSearchCV(svc_poly, param_grid_poly, scoring=\"accuracy\" , n_jobs=3, cv=cv_inner)\n",
    "\n",
    "grid_linear, grid_rbf, grid_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19802\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=2 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of folds must be of Integral type. [1 1 1 ... 0 0 0] of type <class 'numpy.ndarray'> was passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-7a791f82a96f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# split the dataset in two equal part respecting label proportions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_s5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_s5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_s5_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    638\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m         super().__init__(n_splits=n_splits, shuffle=shuffle,\n\u001b[0m\u001b[0;32m    641\u001b[0m                          random_state=random_state)\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_splits, shuffle, random_state)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m             raise ValueError('The number of folds must be of Integral type. '\n\u001b[0m\u001b[0;32m    277\u001b[0m                              \u001b[1;34m'%s of type %s was passed.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                              % (n_splits, type(n_splits)))\n",
      "\u001b[1;31mValueError\u001b[0m: The number of folds must be of Integral type. [1 1 1 ... 0 0 0] of type <class 'numpy.ndarray'> was passed."
     ]
    }
   ],
   "source": [
    "# split the dataset in two equal part respecting label proportions\n",
    "train_s5, test_s5 = iter(StratifiedKFold(y_s5_enc, 2)).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': gamma_range ,\n",
    "                     'C': C_range},\n",
    "                    {'kernel': ['linear'], 'C': C_range} ]\n",
    "\n",
    "scores = [\n",
    "    ('precision', precision_score),\n",
    "    ('recall', recall_score),\n",
    "]\n",
    "\n",
    "for score_name, score_func in scores:\n",
    "    clf = GridSearchCV(SVC(C=1), tuned_parameters, n_jobs=2,\n",
    "                       score_func=score_func)\n",
    "    clf.fit(X[train], y[train], cv=StratifiedKFold(y[train], 5))\n",
    "    y_true, y_pred = y[test], clf.predict(X[test])\n",
    "\n",
    "    print \"Classification report for the best estimator: \"\n",
    "    print clf.best_estimator\n",
    "    print \"Tuned for '%s' with optimal value: %0.3f\" % (\n",
    "        score_name, score_func(y_true, y_pred))\n",
    "    print classification_report(y_true, y_pred)\n",
    "    print \"Grid scores:\"\n",
    "    pprint(clf.grid_points_scores_)\n",
    "    print\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Gamma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 161.87079310417175 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# execute the nested cross-validation\n",
    "start_time = time.time()\n",
    "scores_s5_lgnac_linear = cross_val_score(grid_linear, X_s5_lgnac, y_s5_enc, scoring='accuracy', cv=cv_outer, n_jobs=3)\n",
    "print(\"--- linear kernel, 5%: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# execute the nested cross-validation\n",
    "start_time = time.time()\n",
    "scores_s15_lgnac_linear = cross_val_score(grid_linear, X_s15_lgnac, y_s15_enc, scoring='accuracy', cv=cv_outer, n_jobs=3)\n",
    "print(\"---  linear kernel, 15%: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print('[NAc] SVM w/ Linear kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s5_lgnac_linear), std(scores_s5_lgnac_linear)))\n",
    "print('[NAc] SVM w/ Linear kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s15_lgnac_linear), std(scores_s15_lgnac_linear)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  rbf kernel, 921.988338470459 seconds ---\n",
      "---  rbf kernel, 971.9893679618835 seconds ---\n",
      "[NAc] SVM w/ RBF kernel, Accuracy: 0.592 (0.006)\n",
      "[NAc] SVM w/ RBF kernel, Accuracy: 0.566 (0.010)\n"
     ]
    }
   ],
   "source": [
    "# execute the nested cross-validation\n",
    "start_time = time.time()\n",
    "scores_s5_lgnac_rbf = cross_val_score(grid_rbf, X_s5_lgnac, y_s5_enc, scoring='accuracy', cv=cv_outer, n_jobs=3)\n",
    "print(\"---  rbf kernel, %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# execute the nested cross-validation\n",
    "start_time = time.time()\n",
    "scores_s15_lgnac_rbf = cross_val_score(grid_rbf, X_s15_lgnac, y_s15_enc, scoring='accuracy', cv=cv_outer, n_jobs=3)\n",
    "print(\"---  rbf kernel, %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print('[NAc] SVM w/ RBF kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s5_lgnac_rbf), std(scores_s5_lgnac_rbf)))\n",
    "print('[NAc] SVM w/ RBF kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s15_lgnac_rbf), std(scores_s15_lgnac_rbf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59739732 0.60170871 0.58787632 0.58543531 0.58706265]\n"
     ]
    }
   ],
   "source": [
    "print(scores_s5_lgnac_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57148643 0.56824625 0.55388979 0.57982172 0.55551053]\n"
     ]
    }
   ],
   "source": [
    "print(scores_s15_lgnac_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_s15_lgnac, y_s15_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(X_s15_lgnac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(tree.predict(X_s15_lgnac) - y_s15_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92502588, 0.01745531, 0.05751881])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12342x11589 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 298776 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.decision_path(X_s15_lgnac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict_proba(X_s15_lgnac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6921,  7069,  5827, ..., 10313, 10777, 10817], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.apply(X_s15_lgnac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 5795)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.get_depth(), tree.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Time(s)', 'PFC_delta', 'PFC_theta', 'PFC_alpha', 'PFC_beta',\n",
       "       'PFC_low_gamma', 'PFC_high_gamma', 'BLA_delta', 'BLA_theta',\n",
       "       'BLA_alpha', 'BLA_beta', 'BLA_low_gamma', 'BLA_high_gamma',\n",
       "       'NAc_delta', 'NAc_theta', 'NAc_alpha', 'NAc_beta', 'NAc_low_gamma',\n",
       "       'NAc_high_gamma', 'vHip_delta', 'vHip_theta', 'vHip_alpha',\n",
       "       'vHip_beta', 'vHip_low_gamma', 'vHip_high_gamma', 'Reward',\n",
       "       'MouseId', 'Treatment'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 179.26610684394836 seconds ---\n",
      "--- 158.3305902481079 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# execute the nested cross-validation\n",
    "start_time = time.time()\n",
    "scores_s5_lghip_linear = cross_val_score(grid_linear, X_s5_lghip, y_s5_enc, scoring='accuracy', cv=cv_outer, n_jobs=3)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# execute the nested cross-validation\n",
    "start_time = time.time()\n",
    "scores_s15_lghip_linear = cross_val_score(grid_linear, X_s15_lghip, y_s15_enc, scoring='accuracy', cv=cv_outer, n_jobs=3)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Results for, LOW GAMMA \n",
      "\n",
      "[INFO] Water vs. Sucrose 5%: \n",
      "[NAc] SVM w/ Linear kernel, Accuracy: 0.539 (0.046)\n",
      "[NAc] SVM w/ RBF kernel, Accuracy: 1.000 (0.000)\n",
      "[vHIP] SVM w/ Linear kernel, Accuracy: 0.564 (0.054)\n",
      "\n",
      "[INFO] Water vs. Sucrose 15%: \n",
      "[NAc] SVM w/ Linear kernel, Accuracy: 0.658 (0.014)\n",
      "[vHIP] SVM w/ Linear kernel, Accuracy: 0.656 (0.008)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Low gamma\n",
    "print(\"\\n\\n[INFO] Results for, LOW GAMMA \")\n",
    "\n",
    "print(\"\\n[INFO] Water vs. Sucrose 5%: \")\n",
    "print('[NAc] SVM w/ Linear kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s5_lgnac_linear), std(scores_s5_lgnac_linear)))\n",
    "print('[NAc] SVM w/ RBF kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s5_lgnac_rbf), std(scores_s5_lgnac_rbf)))\n",
    "print('[vHIP] SVM w/ Linear kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s5_lghip_linear), std(scores_s5_lghip_linear)))\n",
    "\n",
    "print(\"\\n[INFO] Water vs. Sucrose 15%: \")\n",
    "print('[NAc] SVM w/ Linear kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s15_lgnac_linear), std(scores_s15_lgnac_linear)))\n",
    "print('[vHIP] SVM w/ Linear kernel, Accuracy: %.3f (%.3f)' % (mean(scores_s15_lghip_linear), std(scores_s15_lghip_linear)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
