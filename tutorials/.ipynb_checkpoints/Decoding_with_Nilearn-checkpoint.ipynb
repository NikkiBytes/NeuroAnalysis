{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e38534-c5c7-486d-8d9e-692d2b883aaf",
   "metadata": {},
   "source": [
    "# Decoding fMRI Scans with Nilearn  \n",
    "Decoding fMRI task scans with an Support Vector Machine (SVM) classifier and cross-validation (CV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f17b1-02b6-439f-b153-0ef0708304eb",
   "metadata": {},
   "source": [
    "# Data Setup  \n",
    "Decoding an fMRI scan requires a set of inputs: \n",
    "* image mask (`.nii`),\n",
    "* behavioral stimulus file (`.csv`),\n",
    "* fMRI nifti image (`.nii`)   \n",
    "  \n",
    "  \n",
    "To setup the files for this please see the corresponding script: [SCRIPT]()\n",
    "\n",
    "*It is assumed the data is setup correctly with corresponding dimensions.*    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737fab50-81cc-4ce5-bfa2-144e79366f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Input Data \n",
    "#image mask\n",
    "imag_mask='/projects/niblab/bids_projects/Experiments/ChocoData/images/bin_mask.nii.gz'\n",
    "#our behavioral csv file\n",
    "stim = '/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/milkshake_all.csv'\n",
    "#our dataset concatenated image\n",
    "dataset='/projects/niblab/bids_projects/Experiments/ChocoData/images/milkshake_all.nii.gz '\n",
    "#load behavioral data into a pandas df\n",
    "behavioral = pd.read_csv(stim, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb117fa-4eb6-4630-b200-ec37bc13a126",
   "metadata": {},
   "source": [
    "For Chocolate milkshake we combine the taste recipients  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c5bf2-3f45-4cf0-9d31-f48a6a116e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab conditional labels and set up milkshake\n",
    "behavioral[\"Label\"] = behavioral.replace(['HF_LS_receipt', 'LF_HS_receipt', 'HF_HS_receipt'], 'milkshake')\n",
    "y = behavioral[\"Label\"]\n",
    "print(y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66e045-1ac1-4c75-b579-fd6145715186",
   "metadata": {},
   "source": [
    "In our behavioral stimulus file we have multiple task conditions. Not all of the data will be of interest, therefore we can restrict the data to the fMRI signals we want.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fde0b3-156b-45df-83e4-e6792e3d436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restrict data to our target analysis\n",
    "condition_mask = behavioral[\"Label\"].isin(['milkshake', \"h20_receipt\"])\n",
    "y = y[condition_mask]\n",
    "\n",
    "#confirm we have the # of condtions needed\n",
    "print(y.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62362d01-e0e9-4d9c-8707-1276514613f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e60cc-4b0e-4991-94e9-af79e6b6ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masker = NiftiMasker(mask_img=imag_mask, standardize=True, memory=\"nilearn_cache\", memory_level=3)\n",
    "X = masker.fit_transform(dataset)\n",
    "# Apply our condition_mask\n",
    "X = X[condition_mask]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd754a7e-58ad-459d-a33b-0804f26a0bd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d670a460-e328-4fa0-8566-e720ddde87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "svc = SVC(kernel='linear', max_iter=1500)\n",
    "feature_selection = SelectKBest(f_classif, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc4193-dc54-4315-9add-5d80037912d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275941a6-842f-4bf6-9478-1933f214c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have our classifier (SVC), our feature selection (SelectKBest), and now,\n",
    "# we can plug them together in a *pipeline* that performs the two operations\n",
    "# successively:\n",
    "from sklearn.pipeline import Pipeline\n",
    "anova_svc = Pipeline([('anova', feature_selection), ('svc', svc)])\n",
    "anova_svc.fit(X,y)\n",
    "y_pred = anova_svc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e1e39-ddd4-4766-92a8-e595e981ecda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3362291-2e47-476b-8084-ef09f01d2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "print(\"running nested CV......\")\n",
    "k_range = [ 15, 50, 150, 500, 1000, 3000, 5000]\n",
    "grid = GridSearchCV(anova_svc, param_grid={'anova__k': k_range}, verbose=1, cv=5, n_jobs=4)\n",
    "nested_cv_scores = cross_val_score(grid, X, y, cv=5, n_jobs=4)\n",
    "#NEST_SCORE = np.mean(nested_cv_scores)\n",
    "print(\"Nested CV score: %.4f\" % np.mean(nested_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512a7ade-c886-4a3c-b8be-1ec3ca9c038e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07d204-c156-4ea6-9ca7-81f5b7820a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the image\n",
    "coef = svc.coef_\n",
    "# reverse feature selection\n",
    "coef = feature_selection.inverse_transform(coef)\n",
    "# reverse masking\n",
    "weight_img = masker.inverse_transform(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df17ef3-4041-4a62-b140-9e610902dd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32a4f1-1308-44fc-9f8c-4cc37a5b0bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the mean image as a background to avoid relying on anatomical data\n",
    "from nilearn import image\n",
    "mean_img = image.mean_img(dataset)\n",
    "mean_img.to_filename('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/4w_p2_mean_nimask.nii')\n",
    "\n",
    "# Create the figure\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "display = plot_stat_map(weight_img, mean_img, title='Milkshake vs. H2O')\n",
    "display.savefig('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/4w_p2_SVM_nimask.png')\n",
    "# Saving the results as a Nifti file may also be important\n",
    "weight_img.to_filename('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives/code/decoding/milkshake_vs_h2O/images/4w_p2_SVM_nimask.nii')\n",
    "print(\"Time: \", (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088959ad-4ae7-4556-94bb-c76f4197edce",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
