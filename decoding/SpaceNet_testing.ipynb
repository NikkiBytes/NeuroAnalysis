{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nikkibytes/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing packages \n",
    "import os\n",
    "import numpy as np\n",
    "import nilearn\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nilearn.input_data import NiftiMasker \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from nilearn.image import index_img\n",
    "\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.use('Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rest' 'h20_pic' 'h20_receipt' 'milkshake_pic' 'HF_LS_receipt' 'rinse'\n",
      " 'LF_LS_receipt' 'LF_HS_receipt' 'HF_HS_receipt']\n",
      "['rest' 'h20_pic' 'h20_receipt' 'milkshake_pic' 'milkshake' 'rinse']\n",
      "['h20_receipt' 'milkshake']\n"
     ]
    }
   ],
   "source": [
    "#image mask\n",
    "imag_mask='/Users/nikkibytes/Documents/lab/test_imgs/bin_mask.nii.gz'\n",
    "\n",
    "#our behavioral csv file \n",
    "stim = '/Users/nikkibytes/Documents/lab/test_imgs/sub-001.csv'\n",
    "\n",
    "#our dataset concatenated image \n",
    "dataset='/Users/nikkibytes/Documents/lab/test_imgs/sub-001.nii.gz'\n",
    "\n",
    "#load behavioral data into a pandas df\n",
    "behavioral = pd.read_csv(stim, sep=\"\\t\")\n",
    "print(behavioral[\"Label\"].unique())\n",
    "\n",
    "\n",
    "#grab conditional labels and set up milkshake\n",
    "behavioral[\"Label\"] = behavioral.replace(['HF_LS_receipt', 'LF_LS_receipt', 'LF_HS_receipt', 'HF_HS_receipt'], 'milkshake')\n",
    "\n",
    "\n",
    "y = behavioral[\"Label\"]\n",
    "print(y.unique()) # make sure all the milkshake receipts have been replaced with \"milkshake\"\n",
    "\n",
    "\n",
    "#restrict data to our target analysis \n",
    "condition_mask = behavioral[\"Label\"].isin(['milkshake', \"h20_receipt\"])\n",
    "y = y[condition_mask]\n",
    "\n",
    "\n",
    "#confirm we have the # of condtions needed\n",
    "print(y.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 74, 49, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Split data into train and test samples, using the chunks\n",
    "condition_mask_train = (condition_mask) & (behavioral['sess'] == 0)\n",
    "condition_mask_test = (condition_mask) & (behavioral['sess']  == 1)\n",
    "\n",
    "\n",
    "# Apply this sample mask to X (fMRI data) and y (behavioral labels)\n",
    "# Because the data is in one single large 4D image, we need to use\n",
    "# index_img to do the split easily\n",
    "X_train = index_img(dataset, condition_mask_train)\n",
    "X_test = index_img(dataset, condition_mask_test)\n",
    "y_train = y[condition_mask_train]\n",
    "y_test = y[condition_mask_test]\n",
    "\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.fit] Loading data from None\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti2Image(\n",
      "shape=(63, 74, 49, 2361),\n",
      "affine=array([[   3.125,    0.   ,    0.   ,  -96.   ],\n",
      "       [   0.   ,    3.125,    0.   , -132.   ],\n",
      "       [   0.   ,    0.   ,    4.   ,  -78.   ],\n",
      "       \n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.decoding.space_net.path_scores...\n",
      "path_scores(<function _graph_net_logistic at 0x117f46d08>, memmap([[ 1.570759, ..., -0.576198],\n",
      "        ...,\n",
      "        [-0.664723, ..., -0.576198]]), \n",
      "array([-1, ...,  1]), array([[[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]]]), \n",
      "None, [0.5], array([ 295, ..., 2360]), array([  0, ..., 363]), {'max_iter': 1000, 'tol': 0.0001}, n_alphas=10, eps=0.001, is_classif=True, key=(0, 0), debias=False, verbose=1, screening_percentile=14.033366573665733)\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.decoding.space_net.path_scores...\n",
      "path_scores(<function _graph_net_logistic at 0x117f46d08>, memmap([[ 1.570759, ..., -0.576198],\n",
      "        ...,\n",
      "        [-0.664723, ..., -0.576198]]), \n",
      "array([-1, ...,  1]), array([[[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]]]), \n",
      "None, [0.5], array([   0, ..., 2360]), array([295, ..., 592]), {'max_iter': 1000, 'tol': 0.0001}, n_alphas=10, eps=0.001, is_classif=True, key=(0, 1), debias=False, verbose=1, screening_percentile=14.033366573665733)\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.decoding.space_net.path_scores...\n",
      "path_scores(<function _graph_net_logistic at 0x117f46d08>, memmap([[ 1.570759, ..., -0.576198],\n",
      "        ...,\n",
      "        [-0.664723, ..., -0.576198]]), \n",
      "array([-1, ...,  1]), array([[[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]]]), \n",
      "None, [0.5], array([   0, ..., 2360]), array([591, ..., 956]), {'max_iter': 1000, 'tol': 0.0001}, n_alphas=10, eps=0.001, is_classif=True, key=(0, 2), debias=False, verbose=1, screening_percentile=14.033366573665733)\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling nilearn.decoding.space_net.path_scores...\n",
      "path_scores(<function _graph_net_logistic at 0x117f46d08>, memmap([[ 1.570759, ..., -0.576198],\n",
      "        ...,\n",
      "        [-0.664723, ..., -0.576198]]), \n",
      "array([-1, ...,  1]), array([[[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[False, ..., False],\n",
      "        ...,\n",
      "        [False, ..., False]]]), \n",
      "None, [0.5], array([   0, ..., 2360]), array([ 886, ..., 1253]), {'max_iter': 1000, 'tol': 0.0001}, n_alphas=10, eps=0.001, is_classif=True, key=(0, 3), debias=False, verbose=1, screening_percentile=14.033366573665733)\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean epi to be used for the background of the plotting\n",
    "from nilearn.image import mean_img\n",
    "background_img = mean_img(dataset)\n",
    "\n",
    "from nilearn.decoding import SpaceNetClassifier\n",
    "# Fit model on train data and predict on test data\n",
    "decoder = SpaceNetClassifier(memory_level=2, n_jobs=4,\n",
    "                             mask=imag_mask, standardize=True,\n",
    "                             memory=\"nilearn_cache\", penalty='graph-net')\n",
    "decoder.fit(X_train, y_train)\n",
    "y_pred = decoder.predict(X_test)\n",
    "accuracy = (y_pred == y_test).mean() * 100.\n",
    "print(\"Graph-net classification accuracy : %g%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
