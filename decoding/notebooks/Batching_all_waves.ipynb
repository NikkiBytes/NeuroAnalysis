{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting all available data\n",
    "#### 133 subjects in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILENAME=\"all_batch1.nii.gz\"\n",
    "\n",
    "DERIV_DIR = '/projects/niblab/bids_projects/Experiments/ChocoData/derivatives'\n",
    "outpath = \"/projects/niblab/bids_projects/Experiments/ChocoData/images\"\n",
    "\n",
    "sub_list=[]\n",
    "all_func = sorted(glob.glob(os.path.join(DERIV_DIR, \"sub-*\", \"ses-*\", \"func/Analysis/feat1/task*/filtered_func_data.nii.gz\")))\n",
    "for x in all_func:\n",
    "    if x.split(\"/\")[-7] not in sub_list:\n",
    "        sub_list.append(x.split(\"/\")[-7])\n",
    "        #print(sub_list)\n",
    "\n",
    "    \n",
    "chunks = [sub_list[x:x+7] for x in range(0, len(sub_list), 7)]\n",
    "for i,chunk in enumerate(chunks):\n",
    "    batch = i + 1\n",
    "    filename = \"all_waves_b%s\"%(batch)\n",
    "    nifti_name = filename+\".nii.gza\"\n",
    "    print(filename)\n",
    "    #print(nifti_name)\n",
    "    if os.path.exists(os.path.join(outpath,nifti_name)):\n",
    "        pass\n",
    "    else:\n",
    "        print('here')\n",
    "        all_func = []\n",
    "        subj_dict = {}\n",
    "        for x in chunk: \n",
    "            subj_dict[x] = [] \n",
    "        #print(subj_dict)\n",
    "    \n",
    "    \n",
    "# iterate through subjects in chunk list\n",
    "        for sub_id in chunk:\n",
    "            all_funcs = sorted(glob.glob(os.path.join(DERIV_DIR, sub_id, \"ses-*\", \"func/Analysis/feat1/task*/filtered_func_data.nii.gz\")))\n",
    "# add each file from the functionals to a temp list to make nifti image\n",
    "            for file in all_funcs:\n",
    "                #print(file)\n",
    "                all_func.append(file)\n",
    "        #count=0\n",
    "        #for fun_ in all_func:\n",
    "         #   print(fun_)\n",
    "          #  count = count +1 \n",
    "        #print(count)\n",
    "\n",
    "\n",
    "#all_func = sorted(all_func[:54])\n",
    "\n",
    "#load in all the files from the glob above, then convert them from nifti1 to nifti2\\n\",\n",
    "        ni2_funcs = (nib.Nifti2Image.from_image(nib.load(func)) for func in all_func)\n",
    "#concat, this is with nibabel, but should work with nilearn too\n",
    "        ni2_concat = nib.concat_images(ni2_funcs, check_affines=False, axis=3)\n",
    "#set the output file name\n",
    "\n",
    "        outfile=os.path.join(outpath,nifti_name)\n",
    "#write the file\n",
    "        ni2_concat.to_filename(outfile)\n",
    "    \n",
    "    \n",
    "    # -add corresponding milkshake label    \n",
    "        ct=0\n",
    "        for d in subj_dict:\n",
    "            task_dirs = glob.glob(os.path.join('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives', d, \"ses-*/func/Analysis/feat1/*\"))\n",
    "            for task in task_dirs:\n",
    "                dir_name = task.split(\"/\")[-1]\n",
    "                sess = task.split(\"/\")[-5]\n",
    "                mlk = dir_name.split(\".\")[0].split(\"e\")[1]\n",
    "                id_ = sess+\"_\"+mlk\n",
    "                subj_dict[d].append(id_)\n",
    "                ct=ct+1\n",
    "        \n",
    "        temp_out = \"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp\"\n",
    "        for sub in subj_dict:\n",
    "            file = open(temp_out+\"/tempfile_%s.txt\"%sub, 'a')\n",
    "            for label in sorted(subj_dict[sub]):\n",
    "                fileX = '/projects/niblab/data/eric_data/ev_files/milkshake/mk%s_attr.txt'%label.split(\"_\")[1]\n",
    "                fileX_contents = open(fileX, 'r')\n",
    "                data = fileX_contents.read()\n",
    "                fileX_contents.close()\n",
    "                file.write(data)\n",
    "            file.close()\n",
    "    \n",
    "        tempfiles=sorted(glob.glob(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_*.txt\"))\n",
    "\n",
    "# fill in 20% of test files \n",
    "        test_slice_count = round(len(tempfiles) *.2)\n",
    "        test_slice = chunk[:test_slice_count]\n",
    "        for sub in test_slice:\n",
    "            df=pd.read_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_%s.txt\"%sub, sep=' ',header=None)\n",
    "            df[1].replace(0,1, inplace=True)\n",
    "            print(df.head())\n",
    "            df.to_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_%s.txt\"%sub, sep=' ', index=False, header=None)    \n",
    "\n",
    "# Make initial text file    \n",
    "        fileout = open(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/%s.txt\"%(filename), \"a\")\n",
    "        fileout.write(\"Label sess\\n\")\n",
    "       \n",
    "        for f in tempfiles:\n",
    "            print(\"adding file %s\"%f)\n",
    "            f_contents = open(f, \"r\")\n",
    "            data=f_contents.read()\n",
    "            f_contents.close()\n",
    "            fileout.write(data)\n",
    "    \n",
    "        fileout.close()\n",
    "# Make final CSV \n",
    "# MAKE CSV FILE WITH PANDAS\n",
    "        import pandas as pd\n",
    "        df=pd.read_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/%s.txt\"%(filename), sep=' ')\n",
    "        df.to_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/%s.csv\"%(filename), sep='\\t', index=False)\n",
    "        for file_ in tempfiles:\n",
    "            os.remove(file_)\n",
    "\n",
    "\n",
    "    \n",
    "# Make the Behavioral \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = [] \n",
    "for x in all_func:\n",
    "    if x.split('/')[-7] not in sub_list:\n",
    "        sub_list.append(x.split('/')[-7])\n",
    "subj_dict = {}\n",
    "for x in sub_list: \n",
    "    subj_dict[x] = [] \n",
    "    \n",
    "# -add corresponding milkshake label    \n",
    "ct=0\n",
    "for d in subj_dict:\n",
    "    task_dirs = glob.glob(os.path.join('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives', d, \"ses-*/func/Analysis/feat1/*\"))\n",
    "    for task in task_dirs:\n",
    "        dir_name = task.split(\"/\")[-1]\n",
    "        sess = task.split(\"/\")[-5]\n",
    "        mlk = dir_name.split(\".\")[0].split(\"e\")[1]\n",
    "        id_ = sess+\"_\"+mlk\n",
    "        subj_dict[d].append(id_)\n",
    "        ct=ct+1\n",
    "        \n",
    "temp_out = \"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp\"\n",
    "for sub in subj_dict:\n",
    "    file = open(temp_out+\"/tempfile_%s.txt\"%sub, 'a')\n",
    "    for label in sorted(subj_dict[sub]):\n",
    "        fileX = '/projects/niblab/data/eric_data/ev_files/milkshake/mk%s_attr.txt'%label.split(\"_\")[1]\n",
    "        fileX_contents = open(fileX, 'r')\n",
    "        data = fileX_contents.read()\n",
    "        fileX_contents.close()\n",
    "        file.write(data)\n",
    "    file.close()\n",
    "    \n",
    "tempfiles=sorted(glob.glob(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_*.txt\"))\n",
    "\n",
    "# fill in 20% of test files \n",
    "test_slice_count = round(len(tempfiles) *.2)\n",
    "test_slice = sub_list[:test_slice_count]\n",
    "for sub in test_slice:\n",
    "    df=pd.read_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_%s.txt\"%sub, sep=' ',header=None)\n",
    "    df[1].replace(0,1, inplace=True)\n",
    "    print(df.head())\n",
    "    df.to_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_%s.txt\"%sub, sep=' ', index=False, header=None)    \n",
    "\n",
    "# Make initial text file    \n",
    "fileout = open(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/all_waves_b1.txt\", \"a\")\n",
    "fileout.write(\"Label sess\\n\")\n",
    "       \n",
    "for f in tempfiles:\n",
    "    print(\"adding file %s\"%f)\n",
    "    f_contents = open(f, \"r\")\n",
    "    data=f_contents.read()\n",
    "    f_contents.close()\n",
    "    fileout.write(data)\n",
    "    \n",
    "fileout.close()\n",
    "# Make final CSV \n",
    "# MAKE CSV FILE WITH PANDAS\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/all_waves_b1.txt\", sep=' ')\n",
    "df.to_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/all_waves_b1.csv\", sep='\\t', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM decoding took 13 hours for these 9 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME=\"all_batch1.nii.gz\"\n",
    "\n",
    "DERIV_DIR = '/projects/niblab/bids_projects/Experiments/ChocoData/derivatives'\n",
    "outpath = \"/projects/niblab/bids_projects/Experiments/ChocoData/images\"\n",
    "all_func = sorted(glob.glob(os.path.join(DERIV_DIR, \"sub-*\", \"ses-*\", \"func/Analysis/feat1/task*/filtered_func_data.nii.gz\")))\n",
    "\n",
    "sub_list = [] \n",
    "for x in all_func:\n",
    "    if x.split('/')[-7] not in sub_list:\n",
    "        sub_list.append(x.split('/')[-7])\n",
    "subj_dict = {}\n",
    "for x in sub_list: \n",
    "    subj_dict[x] = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME=\"all_batch0.nii.gz\"\n",
    "\n",
    "DERIV_DIR = '/projects/niblab/bids_projects/Experiments/ChocoData/derivatives'\n",
    "outpath = \"/projects/niblab/bids_projects/Experiments/ChocoData/images\"\n",
    "all_func = sorted(glob.glob(os.path.join(DERIV_DIR, \"sub-*\", \"ses-*\", \"func/Analysis/feat1/task*/filtered_func_data.nii.gz\")))\n",
    "\n",
    "all_func = sorted(all_func[:30])\n",
    "\n",
    "#load in all the files from the glob above, then convert them from nifti1 to nifti2\\n\",\n",
    "ni2_funcs = (nib.Nifti2Image.from_image(nib.load(func)) for func in all_func)\n",
    "#concat, this is with nibabel, but should work with nilearn too\n",
    "ni2_concat = nib.concat_images(ni2_funcs, check_affines=False, axis=3)\n",
    "#set the output file name\n",
    "outfile=os.path.join(outpath,FILENAME)\n",
    "#write the file\n",
    "ni2_concat.to_filename(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = [] \n",
    "for x in all_func:\n",
    "    if x.split('/')[-7] not in sub_list:\n",
    "        sub_list.append(x.split('/')[-7])\n",
    "subj_dict = {}\n",
    "for x in sub_list: \n",
    "    subj_dict[x] = [] \n",
    "    \n",
    "# -add corresponding milkshake label    \n",
    "ct=0\n",
    "for d in subj_dict:\n",
    "    task_dirs = glob.glob(os.path.join('/projects/niblab/bids_projects/Experiments/ChocoData/derivatives', d, \"ses-*/func/Analysis/feat1/*\"))\n",
    "    for task in task_dirs:\n",
    "        dir_name = task.split(\"/\")[-1]\n",
    "        sess = task.split(\"/\")[-5]\n",
    "        mlk = dir_name.split(\".\")[0].split(\"e\")[1]\n",
    "        id_ = sess+\"_\"+mlk\n",
    "        subj_dict[d].append(id_)\n",
    "        ct=ct+1\n",
    "        \n",
    "temp_out = \"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp\"\n",
    "for sub in subj_dict:\n",
    "    file = open(temp_out+\"/tempfile_%s.txt\"%sub, 'a')\n",
    "    for label in sorted(subj_dict[sub]):\n",
    "        fileX = '/projects/niblab/data/eric_data/ev_files/milkshake/mk%s_attr.txt'%label.split(\"_\")[1]\n",
    "        fileX_contents = open(fileX, 'r')\n",
    "        data = fileX_contents.read()\n",
    "        fileX_contents.close()\n",
    "        file.write(data)\n",
    "    file.close()\n",
    "    \n",
    "tempfiles=sorted(glob.glob(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_*.txt\"))\n",
    "\n",
    "# fill in 20% of test files \n",
    "test_slice_count = round(len(tempfiles) *.2)\n",
    "test_slice = sub_list[:test_slice_count]\n",
    "for sub in test_slice:\n",
    "    df=pd.read_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_%s.txt\"%sub, sep=' ',header=None)\n",
    "    df[1].replace(0,1, inplace=True)\n",
    "    print(df.head())\n",
    "    df.to_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/temp/tempfile_%s.txt\"%sub, sep=' ', index=False, header=None)    \n",
    "\n",
    "# Make initial text file    \n",
    "fileout = open(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/all_batch0.txt\", \"a\")\n",
    "fileout.write(\"Label sess\\n\")\n",
    "       \n",
    "for f in tempfiles:\n",
    "    print(\"adding file %s\"%f)\n",
    "    f_contents = open(f, \"r\")\n",
    "    data=f_contents.read()\n",
    "    f_contents.close()\n",
    "    fileout.write(data)\n",
    "    \n",
    "fileout.close()\n",
    "# Make final CSV \n",
    "# MAKE CSV FILE WITH PANDAS\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/all_batch0.txt\", sep=' ')\n",
    "df.to_csv(\"/projects/niblab/bids_projects/Experiments/ChocoData/behavorial_data/all_batch0.csv\", sep='\\t', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
